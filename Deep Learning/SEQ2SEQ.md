### `Encoder` &rarr; `Attention` &rarr; `Transformer`
***
### Sequence-to-Sequence Architecture
- [Encoder Decoder](https://www.youtube.com/watch?v=KiL74WsgxoA&list=PLKnIA16_RmvYuZauWaPlRTC54KxSNLtNn&index=68)
### Attention Mechanism
- [Attention Mechanism in 1 video](https://www.youtube.com/watch?v=rj5V6q6-XUM&list=PLKnIA16_RmvYuZauWaPlRTC54KxSNLtNn&index=69&ab_channel=CampusX)
- [Bahdanau Attention Vs Luong Attention](https://www.youtube.com/watch?v=0hZT4_fHfNQ&list=PLKnIA16_RmvYuZauWaPlRTC54KxSNLtNn&index=71)
### Transformers
- [Introduction to Transformers](https://www.youtube.com/watch?v=BjRVS2wTtcA&list=PLKnIA16_RmvYuZauWaPlRTC54KxSNLtNn&index=72&ab_channel=CampusX)
